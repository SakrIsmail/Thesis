{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722bff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights, fasterrcnn_mobilenet_v3_large_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fab47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_json='/var/scratch/sismail/data/processed/final_annotations.json'\n",
    "image_directory = '/var/scratch/sismail/data/images'\n",
    "\n",
    "test_ratio = 0.2\n",
    "random_seed = 42\n",
    "\n",
    "with open(final_output_json, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "image_filenames = list(annotations['images'].keys())\n",
    "\n",
    "random.seed(random_seed)\n",
    "random.shuffle(image_filenames)\n",
    "\n",
    "num_test = int(len(image_filenames) * test_ratio)\n",
    "test_images = image_filenames[:num_test]\n",
    "train_images = image_filenames[num_test:]\n",
    "\n",
    "train_annotations = {\n",
    "    'all_parts': annotations['all_parts'],\n",
    "    'images': {img_name: annotations['images'][img_name] for img_name in train_images}\n",
    "}\n",
    "\n",
    "test_annotations = {\n",
    "    'all_parts': annotations['all_parts'],\n",
    "    'images': {img_name: annotations['images'][img_name] for img_name in test_images}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f76445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BikePartsDetectionDataset(Dataset):\n",
    "    def __init__(self, annotations_dict, image_dir, transform=None):\n",
    "        self.all_parts = annotations_dict['all_parts']\n",
    "        self.part_to_idx = {part: idx + 1 for idx, part in enumerate(self.all_parts)}\n",
    "        self.idx_to_part = {idx + 1: part for idx, part in enumerate(self.all_parts)}\n",
    "        self.image_data = annotations_dict['images']\n",
    "        self.image_filenames = list(self.image_data.keys())\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.image_filenames[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_filename)\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        annotation = self.image_data[img_filename]\n",
    "        available_parts_info = annotation['available_parts']\n",
    "        missing_parts_names = annotation.get('missing_parts', [])\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for part_info in available_parts_info:\n",
    "            part_name = part_info['part_name']\n",
    "            bbox = part_info['absolute_bounding_box']\n",
    "\n",
    "            xmin = bbox['left']\n",
    "            ymin = bbox['top']\n",
    "            xmax = xmin + bbox['width']\n",
    "            ymax = ymin + bbox['height']\n",
    "\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            labels.append(self.part_to_idx[part_name])\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        missing_labels = torch.tensor([self.part_to_idx[part] for part in missing_parts_names], dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'missing_labels': missing_labels,\n",
    "            'image_id': torch.tensor([idx])\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0904d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = BikePartsDetectionDataset(train_annotations, image_directory, transform=transform)\n",
    "test_dataset = BikePartsDetectionDataset(test_annotations, image_directory, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=lambda batch: tuple(zip(*batch))\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=lambda batch: tuple(zip(*batch))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7098798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  67%|██████▋   | 67/100 [06:00<02:57,  5.38s/batch, loss=3.83]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     20\u001b[39m targets = [{k: v.to(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m t.items()} \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m targets]\n\u001b[32m     22\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m loss_dict = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m losses = \u001b[38;5;28msum\u001b[39m(loss \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m loss_dict.values())\n\u001b[32m     28\u001b[39m losses.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torchvision/models/detection/generalized_rcnn.py:101\u001b[39m, in \u001b[36mGeneralizedRCNN.forward\u001b[39m\u001b[34m(self, images, targets)\u001b[39m\n\u001b[32m     94\u001b[39m             degen_bb: List[\u001b[38;5;28mfloat\u001b[39m] = boxes[bb_idx].tolist()\n\u001b[32m     95\u001b[39m             torch._assert(\n\u001b[32m     96\u001b[39m                 \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     97\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mAll bounding boxes should have positive height and width.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     98\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Found invalid box \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdegen_bb\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for target at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     99\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, torch.Tensor):\n\u001b[32m    103\u001b[39m     features = OrderedDict([(\u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m, features)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torchvision/models/detection/backbone_utils.py:57\u001b[39m, in \u001b[36mBackboneWithFPN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.fpn(x)\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torchvision/models/_utils.py:69\u001b[39m, in \u001b[36mIntermediateLayerGetter.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     67\u001b[39m out = OrderedDict()\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items():\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     x = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_layers:\n\u001b[32m     71\u001b[39m         out_name = \u001b[38;5;28mself\u001b[39m.return_layers[name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torchvision/models/mobilenetv3.py:111\u001b[39m, in \u001b[36mInvertedResidual.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_res_connect:\n\u001b[32m    113\u001b[39m         result += \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/conv.py:458\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/conv.py:454\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m'\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    451\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(F.pad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode),\n\u001b[32m    452\u001b[39m                     weight, bias, \u001b[38;5;28mself\u001b[39m.stride,\n\u001b[32m    453\u001b[39m                     _pair(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups)\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model = fasterrcnn_mobilenet_v3_large_fpn(weights='DEFAULT')\n",
    "\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "num_classes = len(train_dataset.all_parts) + 1\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    with tqdm(train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{num_epochs}\") as tepoch:\n",
    "        for images, targets in tepoch:\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tepoch.set_postfix(loss=losses.item())\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {losses.item()}\")\n",
    "\n",
    "torch.save(model.state_dict(), f\"models/faster r-cnn/fasterrcnn_{num_epochs}_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fbcd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 25/25 [01:07<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image_id': 0, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 18, 11}}, {'image_id': 1, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9}}, {'image_id': 2, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 9, 17, 18, 21}}, {'image_id': 3, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 9, 18, 19, 22}}, {'image_id': 4, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 9, 11, 16, 17, 18, 19, 21, 22}}, {'image_id': 5, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {6, 22}}, {'image_id': 6, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 22, 7}}, {'image_id': 7, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 2, 19, 7}}, {'image_id': 8, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {17, 2, 22, 7}}, {'image_id': 9, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {4, 5, 9, 18, 19, 22}}, {'image_id': 10, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 5, 6, 7, 9, 11, 19, 22}}, {'image_id': 11, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {19}}, {'image_id': 12, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {17, 2, 22, 7}}, {'image_id': 13, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 11, 16, 18, 21}}, {'image_id': 14, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {3, 5, 9, 11, 18, 21}}, {'image_id': 15, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 2, 22, 7}}, {'image_id': 16, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 12, 18, 19, 21}}, {'image_id': 17, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {4, 5, 6, 9, 11, 16, 17, 19, 21, 22}}, {'image_id': 18, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9}}, {'image_id': 19, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {17, 2, 22, 7}}, {'image_id': 20, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': set()}, {'image_id': 21, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {16, 9, 21, 17}}, {'image_id': 22, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 4, 7, 9, 16, 18}}, {'image_id': 23, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 7, 9, 19, 22}}, {'image_id': 24, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {7, 9, 11, 17, 19, 22}}, {'image_id': 25, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 9, 11, 17, 18, 19}}, {'image_id': 26, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {4, 5, 9, 14, 16, 18}}, {'image_id': 27, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {8, 9, 2, 12}}, {'image_id': 28, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {11, 9, 19, 5}}, {'image_id': 29, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9}}, {'image_id': 30, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {3}}, {'image_id': 31, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {16, 9, 2, 7}}, {'image_id': 32, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 11}}, {'image_id': 33, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {11, 19, 5, 22}}, {'image_id': 34, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 21, 22}}, {'image_id': 35, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 9, 18, 19, 22}}, {'image_id': 36, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 9, 11, 14, 22}}, {'image_id': 37, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {16, 9, 11}}, {'image_id': 38, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 22}}, {'image_id': 39, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 18, 5}}, {'image_id': 40, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {3, 5, 9, 13, 16, 18, 19, 21, 22}}, {'image_id': 41, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {4, 5, 6, 9, 11, 15, 16, 18, 19, 21, 22}}, {'image_id': 42, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 11, 15, 16, 17, 18, 19, 21}}, {'image_id': 43, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 22}}, {'image_id': 44, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 18, 19}}, {'image_id': 45, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {21}}, {'image_id': 46, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {16, 9, 8}}, {'image_id': 47, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 18, 22}}, {'image_id': 48, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {19, 5}}, {'image_id': 49, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 7, 9, 17, 19, 22}}, {'image_id': 50, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {11, 18, 19, 5}}, {'image_id': 51, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 5, 7, 9, 17, 19, 22}}, {'image_id': 52, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9}}, {'image_id': 53, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 7, 9, 11, 17, 18, 19, 22}}, {'image_id': 54, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 18, 19, 17}}, {'image_id': 55, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {16}}, {'image_id': 56, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 18, 19, 22}}, {'image_id': 57, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 17, 18, 19, 21}}, {'image_id': 58, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 7}}, {'image_id': 59, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 9, 16, 17, 18, 21}}, {'image_id': 60, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 5}}, {'image_id': 61, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {17, 19, 22}}, {'image_id': 62, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 18, 19}}, {'image_id': 63, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 7, 9, 16, 17, 18, 19, 22}}, {'image_id': 64, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 9, 18, 19, 22}}, {'image_id': 65, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {1, 2, 5}}, {'image_id': 66, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 7, 9, 11, 17, 18, 19, 21, 22}}, {'image_id': 67, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {18, 11, 15}}, {'image_id': 68, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {19, 12}}, {'image_id': 69, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {6, 9, 18, 19, 22}}, {'image_id': 70, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 2, 19}}, {'image_id': 71, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 11, 17}}, {'image_id': 72, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 5, 7, 9, 11, 16, 17, 19, 21, 22}}, {'image_id': 73, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 9, 16, 19, 21, 22}}, {'image_id': 74, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 18, 21}}, {'image_id': 75, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 9, 11, 16, 17, 18, 19, 21, 22}}, {'image_id': 76, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': set()}, {'image_id': 77, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {15, 16, 18, 19, 22}}, {'image_id': 78, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {4, 5, 6, 9, 11, 16, 17, 19, 21, 22}}, {'image_id': 79, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 21, 5}}, {'image_id': 80, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 11, 21}}, {'image_id': 81, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 22, 7}}, {'image_id': 82, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 19, 22, 7}}, {'image_id': 83, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 9, 11, 16, 19, 21}}, {'image_id': 84, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {18, 19, 5, 22}}, {'image_id': 85, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 6, 9, 11, 19, 22}}, {'image_id': 86, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 5, 7, 11, 17, 22}}, {'image_id': 87, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {16, 9, 11}}, {'image_id': 88, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 18, 19, 22}}, {'image_id': 89, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 9, 12, 18, 19, 21}}, {'image_id': 90, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 7, 9, 18, 19, 22}}, {'image_id': 91, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {1, 3, 5, 9, 19, 22}}, {'image_id': 92, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 5, 7, 9, 11, 16, 18, 19, 21, 22}}, {'image_id': 93, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 18, 15}}, {'image_id': 94, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {5, 9, 11, 18, 22}}, {'image_id': 95, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 3, 5, 9, 22}}, {'image_id': 96, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {9, 18, 5}}, {'image_id': 97, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {19, 5, 22}}, {'image_id': 98, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {2, 7, 9, 16, 18, 22}}, {'image_id': 99, 'predicted_missing_parts': {1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, 'true_missing_parts': {4, 5, 9, 11, 16, 17, 18, 19, 21, 22}}]\n",
      "Part: back_pedal\n",
      "  Accuracy: 0.0200\n",
      "  Precision: 0.0200\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.0392\n",
      "\n",
      "  AP:        0.0200\n",
      "\n",
      "Part: back_hand_break\n",
      "  Accuracy: 0.2800\n",
      "  Precision: 0.2800\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.4375\n",
      "\n",
      "  AP:        0.2800\n",
      "\n",
      "Part: front_pedal\n",
      "  Accuracy: 0.0500\n",
      "  Precision: 0.0500\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.0952\n",
      "\n",
      "  AP:        0.0500\n",
      "\n",
      "Part: front_mudguard\n",
      "  Accuracy: 0.0700\n",
      "  Precision: 0.0700\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.1308\n",
      "\n",
      "  AP:        0.0700\n",
      "\n",
      "Part: front_light\n",
      "  Accuracy: 0.4100\n",
      "  Precision: 0.4100\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.5816\n",
      "\n",
      "  AP:        0.4100\n",
      "\n",
      "Part: back_mudguard\n",
      "  Accuracy: 0.0700\n",
      "  Precision: 0.0700\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.1308\n",
      "\n",
      "  AP:        0.0700\n",
      "\n",
      "Part: front_handbreak\n",
      "  Accuracy: 0.2400\n",
      "  Precision: 0.2400\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.3871\n",
      "\n",
      "  AP:        0.2400\n",
      "\n",
      "Part: saddle\n",
      "  Accuracy: 0.0200\n",
      "  Precision: 0.0200\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.0392\n",
      "\n",
      "  AP:        0.0200\n",
      "\n",
      "Part: dress_guard\n",
      "  Accuracy: 0.7300\n",
      "  Precision: 0.7300\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.8439\n",
      "\n",
      "  AP:        0.7300\n",
      "\n",
      "Part: back_wheel\n",
      "  Accuracy: 1.0000\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "  AP:        0.0000\n",
      "\n",
      "Part: lock\n",
      "  Accuracy: 0.3100\n",
      "  Precision: 0.3100\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.4733\n",
      "\n",
      "  AP:        0.3100\n",
      "\n",
      "Part: back_handle\n",
      "  Accuracy: 0.0400\n",
      "  Precision: 0.0400\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.0769\n",
      "\n",
      "  AP:        0.0400\n",
      "\n",
      "Part: chain\n",
      "  Accuracy: 0.0100\n",
      "  Precision: 0.0100\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.0198\n",
      "\n",
      "  AP:        0.0100\n",
      "\n",
      "Part: front_handle\n",
      "  Accuracy: 0.0200\n",
      "  Precision: 0.0200\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.0392\n",
      "\n",
      "  AP:        0.0200\n",
      "\n",
      "Part: front_wheel\n",
      "  Accuracy: 0.0500\n",
      "  Precision: 0.0500\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.0952\n",
      "\n",
      "  AP:        0.0500\n",
      "\n",
      "Part: back_reflector\n",
      "  Accuracy: 0.2500\n",
      "  Precision: 0.2500\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.4000\n",
      "\n",
      "  AP:        0.2500\n",
      "\n",
      "Part: kickstand\n",
      "  Accuracy: 0.2500\n",
      "  Precision: 0.2500\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.4000\n",
      "\n",
      "  AP:        0.2500\n",
      "\n",
      "Part: bell\n",
      "  Accuracy: 0.4300\n",
      "  Precision: 0.4300\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.6014\n",
      "\n",
      "  AP:        0.4300\n",
      "\n",
      "Part: back_light\n",
      "  Accuracy: 0.5000\n",
      "  Precision: 0.5000\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "  AP:        0.5000\n",
      "\n",
      "Part: steer\n",
      "  Accuracy: 0.0000\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n",
      "  F1 Score: 0.0000\n",
      "\n",
      "  AP:        0.0000\n",
      "\n",
      "Part: gear_case\n",
      "  Accuracy: 0.2600\n",
      "  Precision: 0.2600\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.4127\n",
      "\n",
      "  AP:        0.2600\n",
      "\n",
      "Part: dynamo\n",
      "  Accuracy: 0.5000\n",
      "  Precision: 0.5000\n",
      "  Recall: 1.0000\n",
      "  F1 Score: 0.6667\n",
      "\n",
      "  AP:        0.5000\n",
      "\n",
      "Overall Accuracy: 0.2505\n",
      "Overall Precision: 0.2148\n",
      "Overall Recall: 1.0000\n",
      "Overall F1 Score: 0.3536\n",
      "Mean Average Precision (mAP): 0.2050\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, data_loader, part_to_idx, device):\n",
    "    model.eval()\n",
    "\n",
    "    all_parts_set = set(part_to_idx.values())\n",
    "    results_per_image = []\n",
    "\n",
    "    for images, targets in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = model(images)\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            pred_parts = set(predictions[i]['labels'].cpu().numpy().tolist())\n",
    "            true_missing_parts = set(targets[i]['missing_labels'].cpu().numpy().tolist())\n",
    "            image_id = targets[i]['image_id'].item()\n",
    "\n",
    "            predicted_missing_parts = all_parts_set - pred_parts\n",
    "\n",
    "            results_per_image.append({\n",
    "                'image_id': image_id,\n",
    "                'predicted_missing_parts': predicted_missing_parts,\n",
    "                'true_missing_parts': true_missing_parts\n",
    "            })\n",
    "\n",
    "    return results_per_image\n",
    "\n",
    "\n",
    "def part_level_evaluation_sklearn(results_per_image, part_to_idx, idx_to_part):\n",
    "    part_indices = list(part_to_idx.values())\n",
    "\n",
    "    part_true = {part: [] for part in part_indices}\n",
    "    part_pred = {part: [] for part in part_indices}\n",
    "\n",
    "    for result in results_per_image:\n",
    "        true_missing = result['true_missing_parts']\n",
    "        predicted_missing = result['predicted_missing_parts']\n",
    "\n",
    "        for part in part_indices:\n",
    "            part_true[part].append(1 if part in true_missing else 0)\n",
    "            part_pred[part].append(1 if part in predicted_missing else 0)\n",
    "\n",
    "    accuracy = {}\n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    f1 = {}\n",
    "\n",
    "    all_true_flat = []\n",
    "    all_pred_flat = []\n",
    "\n",
    "    for part in part_indices:\n",
    "        y_true = part_true[part]\n",
    "        y_pred = part_pred[part]\n",
    "\n",
    "        accuracy[part] = accuracy_score(y_true, y_pred)\n",
    "        precision[part] = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall[part] = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1[part] = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "        all_true_flat.extend(y_true)\n",
    "        all_pred_flat.extend(y_pred)\n",
    "\n",
    "        print(f\"Part: {idx_to_part[part]}\")\n",
    "        print(f\"  Accuracy: {accuracy[part]:.4f}\")\n",
    "        print(f\"  Precision: {precision[part]:.4f}\")\n",
    "        print(f\"  Recall: {recall[part]:.4f}\")\n",
    "        print(f\"  F1 Score: {f1[part]:.4f}\\n\")\n",
    "\n",
    "    overall_accuracy = accuracy_score(all_true_flat, all_pred_flat)\n",
    "    overall_precision = precision_score(all_true_flat, all_pred_flat, zero_division=0)\n",
    "    overall_recall = recall_score(all_true_flat, all_pred_flat, zero_division=0)\n",
    "    overall_f1 = f1_score(all_true_flat, all_pred_flat, zero_division=0)\n",
    "\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "    print(f\"Overall Precision: {overall_precision:.4f}\")\n",
    "    print(f\"Overall Recall: {overall_recall:.4f}\")\n",
    "    print(f\"Overall F1 Score: {overall_f1:.4f}\")\n",
    "\n",
    "    return accuracy, precision, recall, f1, overall_accuracy, overall_precision, overall_recall, overall_f1\n",
    "\n",
    "\n",
    "results_per_image = evaluate_model(model, test_loader, train_dataset.part_to_idx, device)\n",
    "\n",
    "print(results_per_image)\n",
    "\n",
    "accuracy, precision, recall, f1, overall_accuracy, overall_precision, overall_recall, overall_f1 = part_level_evaluation_sklearn(\n",
    "    results_per_image, train_dataset.part_to_idx, train_dataset.idx_to_part\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
